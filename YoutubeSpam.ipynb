{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YoutubeSpam.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPCaPur1j1o2djqEG0gsBIr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daiveeknaik14/Youtube-Spam-Comment-Detection/blob/master/YoutubeSpam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_bz60lpT9sK",
        "colab_type": "code",
        "outputId": "6bd21f28-f90a-477a-cf88-f1a05a7b3173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "import zipfile\n",
        "EMBED_DIMENSION = 50\n",
        "COMMENTS_FT = 'comments_words'\n",
        "comments_df_list = []\n",
        "comments_file = ['Youtube01-Psy.csv','Youtube02-KatyPerry.csv','Youtube03-LMFAO.csv','Youtube04-Eminem.csv','Youtube05-Shakira.csv']\n",
        "for f in comments_file:\n",
        "  df = pd.read_csv(f,header=0)\n",
        "  comments_df_list.append(df)\n",
        "comments_df = pd.concat(comments_df_list)\n",
        "comments_df = comments_df.sample(frac=1.0)\n",
        "print(comments_df.shape)\n",
        "comments_df.head(5)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1956, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COMMENT_ID</th>\n",
              "      <th>AUTHOR</th>\n",
              "      <th>DATE</th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>CLASS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>z12uw5z5roiqel3ds22iifbhbmnijn1qz04</td>\n",
              "      <td>Noah François</td>\n",
              "      <td>2014-11-05T20:15:09</td>\n",
              "      <td>Ahhh, 2 years ago....﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>z124jvczaz3dxhnbc04cffk43oiugj25yzo0k</td>\n",
              "      <td>Epic Gaming</td>\n",
              "      <td>2015-05-28T20:07:20.610000</td>\n",
              "      <td>wierd but funny﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>z123tffrdqzbcd5ft234gznazwrhv1pl3</td>\n",
              "      <td>Nadeen Efein</td>\n",
              "      <td>2014-10-01T21:15:49</td>\n",
              "      <td>hi beaties! i made a new channel please go che...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>z12pwjsybq35ux1kd22cddmjpunribtzf04</td>\n",
              "      <td>Ikram Riani</td>\n",
              "      <td>2015-05-20T18:53:35.943000</td>\n",
              "      <td>I lovet﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>LneaDw26bFtw9HLRdHT6M-zQCNCHF7b6j-vqweZRKh0</td>\n",
              "      <td>GreenStudioMashups</td>\n",
              "      <td>NaN</td>\n",
              "      <td>check out my Eminem &amp;amp; Kid Cudi M a s h up ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      COMMENT_ID  ... CLASS\n",
              "135          z12uw5z5roiqel3ds22iifbhbmnijn1qz04  ...     0\n",
              "1          z124jvczaz3dxhnbc04cffk43oiugj25yzo0k  ...     0\n",
              "176            z123tffrdqzbcd5ft234gznazwrhv1pl3  ...     1\n",
              "393          z12pwjsybq35ux1kd22cddmjpunribtzf04  ...     0\n",
              "182  LneaDw26bFtw9HLRdHT6M-zQCNCHF7b6j-vqweZRKh0  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKsuK_6KaYaR",
        "colab_type": "code",
        "outputId": "7e0f4b6c-415f-40bc-ad38-64a86f4115c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "average_comments_size = int(sum([len(c) for c in comments_df.CONTENT])/comments_df.shape[0])\n",
        "print(average_comments_size)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VSYluMgaeK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DSqKK8mbNiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voc_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(average_comments_size)\n",
        "X_transform = voc_processor.fit_transform(comments_df.CONTENT)\n",
        "X_transform = np.array(list(X_transform))\n",
        "y = comments_df.CLASS.values\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_transform, \n",
        "                                    y, test_size=0.2, random_state=42)\n",
        "n_words = len(voc_processor.vocabulary_)\n",
        "voc_dict = voc_processor.vocabulary_._mapping\n",
        "sorted_vocab = sorted(voc_dict.items(), key = lambda x : x[1])\n",
        "f = open('/tmp/meta.tsv', 'w')\n",
        "for val in sorted_vocab:\n",
        "    f.write(str(val[0]) + \"\\n\")\n",
        "f.close()\n",
        "def get_estimator_spec(input_logits, out_lb, train_predict_m):\n",
        "    preds_cls = tf.argmax(input_logits, 1)\n",
        "    if train_predict_m == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "        mode=train_predict_m,\n",
        "        predictions={\n",
        "            'pred_class': preds_cls,\n",
        "            'pred_prob': tf.nn.softmax(input_logits)\n",
        "        })\n",
        "    tr_l = tf.losses.sparse_softmax_cross_entropy(labels=out_lb, logits=input_logits)\n",
        "    if train_predict_m == tf.estimator.ModeKeys.TRAIN:\n",
        "        adm_opt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
        "        tr_op = adm_opt.minimize(tr_l, global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(train_predict_m, loss=tr_l, train_op=tr_op)\n",
        "    eval_metric_ops = {'accuracy': tf.metrics.accuracy(labels=out_lb, predictions=preds_cls)}\n",
        "    return tf.estimator.EstimatorSpec(train_predict_m, loss=tr_l, train_op=tr_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1sEYcZ3cYy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_model_fn(features, labels, mode):\n",
        "    comments_wd_vec = tf.contrib.layers.embed_sequence(\n",
        "      features[COMMENTS_FT], vocab_size=n_words, embed_dim=EMBED_DIMENSION)\n",
        "    comments_word_list = tf.unstack(comments_wd_vec, axis=1)\n",
        "    \n",
        "    rnn_cell = tf.nn.rnn_cell.GRUCell(average_comments_size)\n",
        "    \n",
        "    _, comments_encoding = tf.nn.static_rnn(rnn_cell, comments_word_list, dtype=tf.float32)\n",
        "    \n",
        "    logits = tf.layers.dense(inputs=comments_encoding, units=2, activation=None)\n",
        "    \n",
        "    return get_estimator_spec(input_logits=logits, out_lb=labels, train_predict_m=mode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rHv5pUEiuS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "a3f3d219-ce8a-42eb-8e09-f88df437e021"
      },
      "source": [
        "run_config = tf.contrib.learn.RunConfig()\n",
        "run_config = run_config.replace(model_dir='/tmp/models/',save_summary_steps=10,log_step_count_steps=10)\n",
        "classifier = tf.estimator.Estimator(model_fn=rnn_model_fn,config=run_config)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0f2e8e94a8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_secs': 600, '_log_step_count_steps': 10, '_protocol': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/models/', '_session_creation_timeout_secs': 7200}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OrHf2QWfO2E",
        "colab_type": "code",
        "outputId": "245ca857-833e-40f1-a413-a7517bd5f326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "      x={COMMENTS_FT: X_train},\n",
        "      y=y_train,\n",
        "      batch_size=128,\n",
        "      num_epochs=None,\n",
        "      shuffle=True)\n",
        "classifier.train(input_fn=train_input_fn, steps=200)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From <ipython-input-44-877c6bc2e12a>:6: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-44-877c6bc2e12a>:8: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From <ipython-input-44-877c6bc2e12a>:10: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/models/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.69446874, step = 1\n",
            "INFO:tensorflow:global_step/sec: 1.61088\n",
            "INFO:tensorflow:loss = 0.6855998, step = 11 (6.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.10041\n",
            "INFO:tensorflow:loss = 1.399494, step = 21 (1.637 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.09557\n",
            "INFO:tensorflow:loss = 0.6865215, step = 31 (1.641 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.16451\n",
            "INFO:tensorflow:loss = 0.6620878, step = 41 (1.622 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.1995\n",
            "INFO:tensorflow:loss = 0.2768373, step = 51 (1.613 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.13082\n",
            "INFO:tensorflow:loss = 0.17076916, step = 61 (1.631 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.1503\n",
            "INFO:tensorflow:loss = 0.16685033, step = 71 (1.626 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.15537\n",
            "INFO:tensorflow:loss = 0.12163082, step = 81 (1.624 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.15676\n",
            "INFO:tensorflow:loss = 0.0698671, step = 91 (1.624 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.26275\n",
            "INFO:tensorflow:loss = 0.015235262, step = 101 (1.597 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.2156\n",
            "INFO:tensorflow:loss = 0.005244254, step = 111 (1.609 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.20239\n",
            "INFO:tensorflow:loss = 0.053147107, step = 121 (1.612 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.14285\n",
            "INFO:tensorflow:loss = 0.03952423, step = 131 (1.628 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.19605\n",
            "INFO:tensorflow:loss = 0.017323127, step = 141 (1.614 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.14127\n",
            "INFO:tensorflow:loss = 0.0031539572, step = 151 (1.632 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.09515\n",
            "INFO:tensorflow:loss = 0.008360725, step = 161 (1.640 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.06071\n",
            "INFO:tensorflow:loss = 0.0041583977, step = 171 (1.651 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.07422\n",
            "INFO:tensorflow:loss = 0.0013496419, step = 181 (1.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 6.22396\n",
            "INFO:tensorflow:loss = 0.0011152041, step = 191 (1.606 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 200 into /tmp/models/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0011056383.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f0f2e6e2dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uryqEiMJj9XG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "828f629e-663d-4f1d-8417-bdf9287cf0af"
      },
      "source": [
        "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "      x={COMMENTS_FT: X_test},\n",
        "      y=y_test,\n",
        "      num_epochs=1,\n",
        "      shuffle=False)\n",
        "preds = classifier.predict(input_fn=test_input_fn)\n",
        "y_predicted = np.array(list(p['pred_class'] for p in preds))\n",
        "y_predicted = y_predicted.reshape(np.array(y_test).shape)\n",
        "\n",
        "acc = metrics.accuracy_score(y_test, y_predicted)\n",
        "print('Accuracy: {0:f}'.format(acc))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/models/model.ckpt-200\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Accuracy: 0.956633\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}